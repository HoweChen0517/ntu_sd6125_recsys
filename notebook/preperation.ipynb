{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\NTU Learn\\\\DATA MINING\\\\ntu_sd6125_recsys'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.sparse import coo_matrix, lil_matrix, csr_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "# import faiss\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import fastparquet\n",
    "import joblib\n",
    "\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_by_user_nums(data, sample_size,data_set):\n",
    "    \n",
    "    if data_set == 'ml-20m':\n",
    "        user_id = 'userId'\n",
    "    elif data_set == 'book_crossing':\n",
    "        user_id = 'User-ID'\n",
    "\n",
    "    user_nums = data.groupby(user_id).size()\n",
    "    # get the msot active users\n",
    "    user_nums = user_nums.sort_values(ascending=False)\n",
    "    user_nums = user_nums[:sample_size]\n",
    "\n",
    "    data = data[data[user_id].isin(user_nums.index)]\n",
    "\n",
    "    return data\n",
    "\n",
    "def sample_by_item_nums(data, sample_size,data_set):\n",
    "        \n",
    "    if data_set == 'ml-20m':\n",
    "        item_id = 'movieId'\n",
    "    elif data_set == 'book_crossing':\n",
    "        item_id = 'ISBN'\n",
    "\n",
    "    item_nums = data.groupby(item_id).size()\n",
    "    # get the msot active users\n",
    "    item_nums = item_nums.sort_values(ascending=False)\n",
    "    item_nums = item_nums[:sample_size]\n",
    "\n",
    "    data = data[data[item_id].isin(item_nums.index)]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book-crossing dataset\n",
    "book_ratings = pd.read_csv('data/book_crossing/ratings_raw.csv')\n",
    "# transfer itemId to integer\n",
    "# map_dict is a pre-defined dictionary that maps ISBN to itemId\n",
    "# with open('data/book_crossing/map_dict.json', 'r') as f:\n",
    "#     map_dict = json.load(f)\n",
    "# book_ratings['ISBN'] = book_ratings['ISBN'].apply(lambda x: map_dict[x])\n",
    "# book_ratings = book_ratings.rename(columns={'User-ID':'userId', 'Book-Rating':'rating','ISBN':'itemId'})\n",
    "books_df = pd.read_csv('data/book_crossing/Books.csv')\n",
    "print(book_ratings.shape[0])\n",
    "print(book_ratings['ISBN'].nunique(), book_ratings['User-ID'].nunique())\n",
    "books = list(pd.unique(books_df['ISBN']))\n",
    "book_ratings = book_ratings[book_ratings['ISBN'].isin(books)]\n",
    "book_ratings = book_ratings[book_ratings['Book-Rating'] != 0]\n",
    "print(book_ratings.shape[0])\n",
    "print(book_ratings['ISBN'].nunique(), book_ratings['User-ID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_dict = dict(zip(books_df['ISBN'].unique(), range(books_df['ISBN'].nunique())))\n",
    "# with open('data/book_crossing/map_dict.json', 'w') as f:\n",
    "#     json.dump(map_dict, f)\n",
    "# # map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ratings_subset = sample_by_user_nums(book_ratings, 3000, 'book_crossing')\n",
    "print(book_ratings_subset['User-ID'].nunique(), book_ratings_subset['ISBN'].nunique(), book_ratings_subset.shape[0])\n",
    "book_ratings_subset = sample_by_item_nums(book_ratings_subset, 25000, 'book_crossing')\n",
    "print(book_ratings_subset['User-ID'].nunique(), book_ratings_subset['ISBN'].nunique(), book_ratings_subset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ratings_subset.to_csv('data/book_crossing/ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_rating_df = pd.read_csv('data/book_crossing/ratings.csv')\n",
    "book_rating_df.loc[:,'Book-Rating'].max(), book_rating_df.loc[:,'Book-Rating'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = pd.read_csv('data/ml-20m/ratings.csv')\n",
    "ml_df.loc[:,'rating'].max(), ml_df.loc[:,'rating'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie-lens dataset\n",
    "ratings = pd.read_csv('data/ml-20m/ratings_raw.csv')\n",
    "ratings.rename(columns={'userId':'userId', 'movieId':'itemId', 'rating':'rating'}, inplace=True)\n",
    "# print('building user-item matrix...')\n",
    "ratings['userId'].nunique(), ratings['itemId'].nunique(), ratings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_subset = sample_by_user_nums(ratings, 3000, 'ml-20m')\n",
    "ratings_subset['userId'].nunique(), ratings_subset['itemId'].nunique(), ratings_subset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_subset.to_csv('data/ml-20m/ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborate Filtering-based Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original data is in the format of ['userId', 'itemId', 'rating', 'timestamp']\n",
    "\n",
    "In order perform CF, we only need the interation record between users and items, thus we consider prepare the data according to following process\n",
    "\n",
    "- train_test_split\n",
    "    - Time Order split\n",
    "    - Random split\n",
    "    - Leave-One(K)-Out split\n",
    "    - Sliding window split\n",
    "\n",
    "- load train/test data into dict form as {user_id: [item_id1, item_id2, ..., item_idn]}\n",
    "\n",
    "- preparing features i.e. similarities (in most cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. rating.csv\n",
    "2. train_ratings.csv\n",
    "3. test_ratings.csv\n",
    "4. user_item_rating_matrix\n",
    "5. user_user_sim_matrix\n",
    "6. item_item_sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "def convert_df_to_dict(trn_data, val_data):\n",
    "\n",
    "    \"\"\"\n",
    "    trn_data: pd.DataFrame, training data\n",
    "    val_data: pd.DataFrame, validation data\n",
    "    \"\"\"\n",
    "\n",
    "    trn_user_items_score = trn_data.groupby('userId').apply(lambda x: dict(zip(x['itemId'], x['rating']))).to_dict()\n",
    "    val_user_items_score = val_data.groupby('userId').apply(lambda x: dict(zip(x['itemId'], x['rating']))).to_dict()\n",
    "\n",
    "    trn_data = trn_data.groupby('userId')['itemId'].apply(list).reset_index()\n",
    "    val_data = val_data.groupby('userId')['itemId'].apply(list).reset_index()\n",
    "\n",
    "    trn_user_items = {}\n",
    "    val_user_items = {}\n",
    "\n",
    "    for user, m_df in zip(*(list(trn_data['userId']), list(trn_data['itemId']))):\n",
    "        trn_user_items[user] = set(m_df)\n",
    "\n",
    "    for user, m_df in zip(*(list(val_data['userId']), list(val_data['itemId']))):\n",
    "        val_user_items[user] = set(m_df)\n",
    "    \n",
    "    return trn_user_items_score, val_user_items_score, trn_user_items, val_user_items\n",
    "\n",
    "def dict_slice(adict, start, end):\n",
    "    keys = adict.keys()\n",
    "    dict_slice = {}\n",
    "    for k in list(keys)[start:end]:\n",
    "        dict_slice[k] = adict[k]\n",
    "    return dict_slice\n",
    "\n",
    "def get_i2u2s_reverse_dict(user_items_score):\n",
    "    item_score_dict = defaultdict(lambda: [0] * len(user_items_score))\n",
    "\n",
    "    user_ids = sorted(user_items_score.keys())\n",
    "\n",
    "    user_index_map = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "\n",
    "    for user_id, items in user_items_score.items():\n",
    "        user_index = user_index_map[user_id]\n",
    "        for item_id, score in items.items():\n",
    "            item_score_dict[item_id][user_index] = score\n",
    "\n",
    "    item_score_dict = dict(item_score_dict)\n",
    "\n",
    "    return item_score_dict\n",
    "\n",
    "def get_i2u_reverse_dict(user_items):\n",
    "    item_users = {}\n",
    "    print('Building item_users reverse dict...')\n",
    "    for user_id, items in tqdm(user_items.items()):\n",
    "        for item in items:\n",
    "            if item not in item_users:\n",
    "                item_users[item] = set()\n",
    "            item_users[item].add(user_id)\n",
    "    return item_users\n",
    "\n",
    "def get_user_item_dict(user_items_score):\n",
    "\n",
    "    user_item_dict = {}\n",
    "    for user_id, items in user_items_score.items():\n",
    "        for item_id, score in items.items():\n",
    "            if user_id not in user_item_dict:\n",
    "                user_item_dict[user_id] = set()\n",
    "            user_item_dict[user_id].add(item_id)\n",
    "\n",
    "    return user_item_dict\n",
    "\n",
    "def convert_df_to_sparse_matrix(rating_df, flag='score'):\n",
    "\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    flag: indicator for whether to use score or binary\n",
    "    ----\n",
    "    Output:\n",
    "    sparse_matrix: scipy.sparse.lil_matrix, user-item matrix\n",
    "    \"\"\"\n",
    "\n",
    "    user_ids = rating_df['userId'].unique()\n",
    "    item_ids = rating_df['itemId'].unique()\n",
    "\n",
    "    user_index_map = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    item_index_map = {item_id: idx for idx, item_id in enumerate(item_ids)}\n",
    "\n",
    "    num_users = len(user_ids)\n",
    "    num_items = len(item_ids)\n",
    "\n",
    "    if flag == 'score':\n",
    "        sparse_matrix = lil_matrix((num_users, num_items))\n",
    "    elif flag == 'binary':\n",
    "        sparse_matrix = lil_matrix((num_users, num_items), dtype=np.int8)\n",
    "\n",
    "    for _, row in tqdm(rating_df.iterrows(), total=rating_df.shape[0], desc=\"Processing ratings\"):\n",
    "        user_id = row['userId']\n",
    "        item_id = row['itemId']\n",
    "        score = row['rating']\n",
    "\n",
    "        user_index = user_index_map[user_id]\n",
    "        item_index = item_index_map[item_id]\n",
    "\n",
    "        if flag == 'score':\n",
    "            sparse_matrix[int(user_index), int(item_index)] = int(score)\n",
    "        elif flag == 'binary':\n",
    "            sparse_matrix[int(user_index), int(item_index)] = 1\n",
    "\n",
    "    sparse_matrix = sparse_matrix.tocsr()\n",
    "\n",
    "    return list(user_ids), list(item_ids), sparse_matrix\n",
    "\n",
    "def save_sparse_matrix(sim_dict, file_name):\n",
    "\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    \n",
    "    for i, related_items in sim_dict.items():\n",
    "        for j, similarity in related_items.items():\n",
    "            row.append(i)\n",
    "            col.append(j)\n",
    "            data.append(similarity)\n",
    "    \n",
    "    row = np.array(row)\n",
    "    col = np.array(col)\n",
    "    data = np.array(data)\n",
    "    \n",
    "    sparse_matrix = coo_matrix((data, (row, col)))\n",
    "    \n",
    "    np.savez(file_name, data=sparse_matrix.data, row=sparse_matrix.row, col=sparse_matrix.col, shape=sparse_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_Test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_random(ratings, test_size=0.2):\n",
    "\n",
    "    trn_data, val_data, _, _ = train_test_split(ratings, ratings, test_size=test_size, random_state=42)\n",
    "\n",
    "    return trn_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PS:**\n",
    "\n",
    "Random split does not conform to the application scenario of the recommendation system, because in real scenarios, future behaviors cannot be randomly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Order split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_timeorder(ratings, test_size=0.2):\n",
    "\n",
    "    ratings_sorted = ratings.sort_values(by = ['userId','timestamp'])\n",
    "\n",
    "    trn_data = pd.DataFrame(columns=ratings_sorted.columns)\n",
    "    val_data = pd.DataFrame(columns=ratings_sorted.columns)\n",
    "\n",
    "    for user_id, group in ratings_sorted.groupby('userId'):\n",
    "\n",
    "        train_size = int(len(group) * (1-test_size))\n",
    "\n",
    "        user_trn = group.iloc[:train_size]\n",
    "        user_val = group.iloc[train_size:]\n",
    "\n",
    "        trn_data = pd.concat([trn_data, user_trn], ignore_index=True)\n",
    "        val_data = pd.concat([val_data, user_val], ignore_index=True)\n",
    "\n",
    "    return trn_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PS:**\n",
    "\n",
    "1. Users with less data: \n",
    "\n",
    "    For users with fewer interactions, the 80% split may result in no data in the test set. You can set a minimum interaction threshold or adjust the split strategy for these users. For example, for users with less than 5 interactions, put all their data in the training set, or use the leave-one-out method (the last one is used as the test set).\n",
    "\n",
    "2. Cold start problem:\n",
    "\n",
    "    a. New users: Users that do not appear in the training set may appear in the test set. Since our split method is based on the chronological order of each user, this situation generally does not occur.\n",
    "\n",
    "    b. New m_df: m_df that do not appear in the training set may appear in the test set. If your model needs to predict the rating of a new movie, you need to include the feature information of the movie in the training set, or use a specific cold start processing method.\n",
    "\n",
    "3. Data leakage: \n",
    "\n",
    "    Since we split according to the chronological order of users, the data in the training set occurs before the test set, avoiding the problem of data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-k-Out split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_leavekout(ratings, k=1):\n",
    "\n",
    "    \"\"\"\n",
    "    k: number of items to leave out for validation\n",
    "    \"\"\"\n",
    "\n",
    "    ratings_sorted = ratings.sort_values(by = ['userId','timestamp'])\n",
    "\n",
    "    trn_data = pd.DataFrame(columns=ratings_sorted.columns)\n",
    "    val_data = pd.DataFrame(columns=ratings_sorted.columns)\n",
    "\n",
    "    for user_id, group in ratings_sorted.groupby('userId'):\n",
    "\n",
    "        trn_data = pd.concat([trn_data, group.iloc[:-k]], ignore_index=True)\n",
    "        val_data = pd.concat([val_data, group.iloc[-k:]], ignore_index=True)\n",
    "\n",
    "    return trn_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featuring Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train-test-split...')\n",
    "trn_data, val_data = train_test_split_random(ratings, test_size=0.2)\n",
    "print('convert_df_to_dict...')\n",
    "trn_user_items_score, val_user_items_score, trn_user_items, val_user_items = convert_df_to_dict(trn_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('convert_df_to_sparse_matrix...')\n",
    "user_index, item_index, all_ratings_matrix = convert_df_to_sparse_matrix(trn_data, flag='score')\n",
    "all_ratings_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = [int(i) for i in user_index]\n",
    "item_index = [int(i) for i in item_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train-test-split...')\n",
    "trn_data, val_data = train_test_split_random(book_ratings, test_size=0.2)\n",
    "print('convert_df_to_dict...')\n",
    "trn_user_items_score, val_user_items_score, trn_user_items, val_user_items = convert_df_to_dict(trn_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('convert_df_to_sparse_matrix...')\n",
    "user_index, item_index, all_ratings_matrix = convert_df_to_sparse_matrix(trn_data, flag='score')\n",
    "all_ratings_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = [int(i) for i in user_index]\n",
    "item_index = [int(i) for i in item_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommend items to users based on similar items:**\n",
    "\n",
    "- Jaccard Similarity\n",
    "\n",
    "$$\n",
    "\\text{sim}(item_{i}, item_{j}) = \\frac{|U_{i} \\cap U_{j}|}{|U_{i} \\cup U_{j}|}\n",
    "$$\n",
    "\n",
    "$ U_i $ and $ U_j $ represent the set of users that interact with item $ i $ and $ j $；\n",
    "\n",
    "The numerator is the number of users that interact with both item $ i $ and $ j $, and the denominator is the total number of users that interact with item $ i $ or item $ j $.\n",
    "\n",
    "- Cosine Similarity\n",
    "\n",
    "2 cases:\n",
    "\n",
    "1. With socring:\n",
    "$$\n",
    "\\text{sim}(item_{i}, item_{j}) = \\frac{\\sum_{u \\in U_{i} \\cap U_{j}} r_{u,i} \\cdot r_{u,j}}{\\sqrt{\\sum_{u \\in U_{i}} r_{u,i}^2} \\cdot \\sqrt{\\sum_{u \\in U_{j}} r_{u,j}^2}}\n",
    "$$\n",
    "\n",
    "$ U_i $ and $ U_j $ represent the set of users who have rated items $ i $ and $ j $ respectively.\n",
    "\n",
    "$ r_{u,i} $ represents the rating of user $ u $ on item $ i $, and $ r_{u,j} $ represents the rating of user $ u $ on item $ j $.\n",
    "\n",
    "The numerator is the product of the user's common ratings for the two items, and the denominator is the product of the modulus lengths of the rating vectors of the two items.\n",
    "\n",
    "2. Withous scoring:\n",
    "\n",
    "$$\n",
    "\\text{sim}(i, j) = \\frac{|U_{i} \\cap U_{j}|}{\\sqrt{|U_{i}| \\cdot |U_{j}|}}\n",
    "$$\n",
    "\n",
    "where $ |U_{i} \\cap U_{j}| $ represents the number of users who have interacted with both item $ i $ and item $ j $, and $ |U_{i}| $ and $ |U_{j}| $ represent the number of users who have interacted with item $ i $ and $ j $, respectively.\n",
    "\n",
    "- Pearson Correlation\n",
    "$$\n",
    "\\text{sim}(item_{i}, item_{j}) = \\frac{\\sum_{u \\in U_{i} \\cap U_{j}} (r_{u,i} - \\bar{r}_{i}) \\cdot (r_{u,j} - \\bar{r}_{j})}{\\sqrt{\\sum_{u \\in U_{i} \\cap U_{j}} (r_{u,i} - \\bar{r}_{i})^2} \\cdot \\sqrt{\\sum_{u \\in U_{i} \\cap U_{j}} (r_{u,j} - \\bar{r}_{j})^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = 'f:\\\\NTU Learn\\\\DATA MINING\\\\DMproject'\n",
    "\n",
    "def get_itemCF_sim_batch(rating_matrix, item_index, batch_size=1000, data_set='ml-20m'):\n",
    "    item_user_matrix = rating_matrix.T  # 使用稀疏矩阵，避免大规模内存使用\n",
    "    items = item_index\n",
    "    num_items = len(items)\n",
    "\n",
    "    output_file = os.path.join(ROOT_PATH, \"data\", data_set, \"item_similarity.joblib\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "        with tqdm(total=num_items // batch_size, desc=\"Calculating item similarities\", unit=\"batch\") as pbar:\n",
    "            try:\n",
    "                similarity_data = {}\n",
    "\n",
    "                for start in range(0, num_items, batch_size):\n",
    "                    end = min(start + batch_size, num_items)\n",
    "                    batch_items = item_user_matrix[start:end, :].toarray().astype(np.float32)\n",
    "                    batch_index = [items[i] for i in range(start, end)]\n",
    "\n",
    "                    # 手动不均匀切割 PQ\n",
    "                    d = item_user_matrix.shape[1]  # 用户数即维度\n",
    "                    m = 8  # 分成 m 个子向量\n",
    "                    base_length = d // m\n",
    "                    remainder = d % m  # 剩余维度\n",
    "\n",
    "                    if remainder > 0:\n",
    "                        # 对于最后的子向量使用剩余维度大小\n",
    "                        sub_vectors = []\n",
    "                        for i in range(m - 1):\n",
    "                            sub_vectors.append(batch_items[:, i * base_length:(i + 1) * base_length])\n",
    "                        sub_vectors.append(batch_items[:, (m - 1) * base_length:])  # 最后一个子向量的长度\n",
    "                    else:\n",
    "                        sub_vectors = np.hsplit(batch_items, m)\n",
    "\n",
    "                    # 训练并使用 PQ\n",
    "                    pq_index = faiss.IndexPQ(d, m, 256)\n",
    "                    pq_index.train(batch_items)\n",
    "                    gpu_res = faiss.StandardGpuResources()  # 初始化 GPU 资源\n",
    "                    gpu_index = faiss.index_cpu_to_gpu(gpu_res, 0, pq_index)\n",
    "\n",
    "                    gpu_index.add(batch_items)\n",
    "\n",
    "                    try:\n",
    "                        # 使用 PQ 进行相似度计算\n",
    "                        D, I = gpu_index.search(batch_items, num_items)\n",
    "                    except ValueError as ve:\n",
    "                        print(f\"ValueError in PQ similarity for batch {start}-{end}: {ve}\")\n",
    "                        continue  # 跳过这个批次，继续下一个\n",
    "                    except MemoryError as me:\n",
    "                        print(f\"MemoryError: {me}\")\n",
    "                        break  # 发生内存错误时退出循环\n",
    "\n",
    "                    for idx, item_id in enumerate(batch_index):\n",
    "                        # 将距离转换为相似度 (1 - 距离, 这里假设距离归一化在 [0,1])\n",
    "                        item_similarity = {\n",
    "                            int(items[other_item_id]): round(1 - float(distance), 4)\n",
    "                            for other_item_id, distance in zip(I[idx][:100], D[idx][:100])\n",
    "                        }\n",
    "\n",
    "                        similarity_data[item_id] = item_similarity\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "                # 使用 joblib 保存相似度矩阵，并启用压缩\n",
    "                joblib.dump(similarity_data, output_file, compress=3)\n",
    "                \n",
    "                print(f\"Item similarity results have been saved to {output_file}\")\n",
    "\n",
    "            except IOError as e:\n",
    "                print(f\"IOError: Failed to open or write to file {output_file}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error while writing to file: {e}\")\n",
    "\n",
    "    except OSError as e:\n",
    "        print(f\"OSError: Failed to create directory for {output_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings_matrix.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_itemCF_sim_batch(all_ratings_matrix, item_index, batch_size=1000, data_set='ml-20m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_itemCF_sim_batch(all_ratings_matrix, user_index, item_index, batch_size=1000, output_file='data/ml-20m/itemCF_sim.pkl'):\n",
    "    item_user_matrix = all_ratings_matrix.T\n",
    "    items = item_index\n",
    "    num_items = len(items)\n",
    "\n",
    "    try:\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        \n",
    "        with tqdm(total=num_items // batch_size, desc=\"Calculating item similarities\", unit=\"batch\") as pbar:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                with open(output_file, mode='wb') as file:\n",
    "                    \n",
    "                    for start in range(0, num_items, batch_size):\n",
    "                        end = min(start + batch_size, num_items)\n",
    "                        batch_items = item_user_matrix[start:end, :]\n",
    "                        batch_index = [item_index[i] for i in range(start, end)]\n",
    "                        \n",
    "                        try:\n",
    "                            # calculate cosine similarity between batch users and all users\n",
    "                            similarity_matrix = cosine_similarity(batch_items, item_user_matrix)\n",
    "                        except ValueError as ve:\n",
    "                            print(f\"ValueError in cosine_similarity for batch {start}-{end}: {ve}\")\n",
    "                            continue  # 跳过这个批次，继续下一个\n",
    "                        except MemoryError as me:\n",
    "                            print(f\"MemoryError: {me}\")\n",
    "                            break  # end the loop if memory error occurs\n",
    "                        \n",
    "                        for idx, item_id in enumerate(batch_index):\n",
    "                            item_similarity = {\n",
    "                                int(other_item_id): round(float(similarity), 4)\n",
    "                                for other_item_id, similarity in zip(items, similarity_matrix[idx])\n",
    "                            }\n",
    "                            \n",
    "                            try:\n",
    "                                # save user similarity to file\n",
    "                                pickle.dump({item_id: item_similarity}, file)\n",
    "                            except pickle.PicklingError as pe:\n",
    "                                print(f\"PicklingError for user {item_id}: {pe}\")\n",
    "                                continue  # skip this user and continue with the next one\n",
    "\n",
    "                        pbar.update(1)\n",
    "\n",
    "            except IOError as e:\n",
    "                print(f\"IOError: Failed to open or write to file {output_file}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error while writing to file: {e}\")\n",
    "    \n",
    "    except OSError as e:\n",
    "        print(f\"OSError: Failed to create directory for {output_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    \n",
    "    print(f\"User similarity results have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'data/ml-20m/itemCF_sim.pkl'\n",
    "get_itemCF_sim_batch(all_ratings_matrix, user_index, item_index, batch_size=1000, output_file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'data/book_crossing/itemCF_sim.pkl'\n",
    "get_itemCF_sim_batch(all_ratings_matrix, user_index, item_index, batch_size=1000, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UserCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommend items to users based on similar users**\n",
    "\n",
    "- Jaccard similarity\n",
    "\n",
    "$$\n",
    "sim_{uv}=\\frac{|N(u) \\cap N(v)|}{|N(u)| \\cup|N(v)|}\n",
    "$$\n",
    "\n",
    "Where $N(u)$, $N(v)$ represent the set of items interacted by user $u$ and user $v$ respectively.\n",
    "\n",
    "For users $u$ and $v$, this formula reflects the ratio of the number of intersections of the two interacted items to the number of unions of the two users' interacted items.\n",
    "\n",
    "- Cosine similarity\n",
    "\n",
    "$$\n",
    "sim_{uv}=\\frac{|N(u) \\cap N(v)|}{\\sqrt{|N(u)|\\cdot|N(v)|}}\n",
    "$$\n",
    "\n",
    "Described from the perspective of vectors, let the matrix $A$ be the user-item interaction matrix, the rows of the matrix represent users, and the columns represent items.\n",
    "\n",
    "Assume that the number of users and items is $m,n$ respectively, the interaction matrix $A$ is a matrix with $m$ rows and $n$ columns.\n",
    "\n",
    "All elements in the matrix are $0/1$. If user $i$ interacts with item $j$, then $A_{i,j}=1$, otherwise it is $0$.\n",
    "\n",
    "The vectors $u,v$ are both one-hot in form, and $u\\cdot v$ represents the vector dot product.\n",
    "\n",
    "The above user-item interaction matrix is ​​very sparse in reality. In order to save memory, the interaction matrix is ​​stored in a **dict**.\n",
    "\n",
    "- Pearson correlation\n",
    "\n",
    "$$\n",
    "sim(u,v)=\\frac{\\sum_{i\\in I}(r_{ui}-\\bar r_u)(r_{vi}-\\bar r_v)}{\\sqrt{\\sum_{i\\in I }(r_{ui}-\\bar r_u)^2}\\sqrt{\\sum_{i\\in I }(r_{vi}-\\bar r_v)^2}}\n",
    "$$\n",
    "\n",
    "Where $r_{ui},r_{vi}$ respectively represent whether user $u$ and user $v$ have interaction with item $i$ (or specific rating value);\n",
    "\n",
    "$\\bar r_u, \\bar r_v$ respectively represent the average number of interactions or ratings of all items interacted by user $u$ and user $v$;\n",
    "\n",
    "Compared with cosine similarity, the Pearson correlation reduces the impact of user rating bias by using the user's average score to correct each independent rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_userCF_sim_batch(all_ratings_matrix, user_index, item_index, batch_size=1000, output_file='data/ml-20m/userCF_sim.pkl'):\n",
    "    user_item_matrix = all_ratings_matrix\n",
    "    users = user_index\n",
    "    num_users = len(users)\n",
    "\n",
    "    try:\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        \n",
    "        with tqdm(total=num_users // batch_size, desc=\"Calculating user similarities\", unit=\"batch\") as pbar:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                with open(output_file, mode='wb') as file:\n",
    "                    \n",
    "                    for start in range(0, num_users, batch_size):\n",
    "                        end = min(start + batch_size, num_users)\n",
    "                        batch_users = user_item_matrix[start:end, :]\n",
    "                        batch_index = [user_index[i] for i in range(start, end)]\n",
    "                        \n",
    "                        try:\n",
    "                            # calculate cosine similarity between batch users and all users\n",
    "                            similarity_matrix = cosine_similarity(batch_users, user_item_matrix)\n",
    "                        except ValueError as ve:\n",
    "                            print(f\"ValueError in cosine_similarity for batch {start}-{end}: {ve}\")\n",
    "                            continue  # 跳过这个批次，继续下一个\n",
    "                        except MemoryError as me:\n",
    "                            print(f\"MemoryError: {me}\")\n",
    "                            break  # end the loop if memory error occurs\n",
    "                        \n",
    "                        for idx, user_id in enumerate(batch_index):\n",
    "                            user_similarity = {\n",
    "                                int(other_user_id): round(float(similarity), 4)\n",
    "                                for other_user_id, similarity in zip(users, similarity_matrix[idx])\n",
    "                            }\n",
    "                            \n",
    "                            try:\n",
    "                                # save user similarity to file\n",
    "                                pickle.dump({user_id: user_similarity}, file)\n",
    "                            except pickle.PicklingError as pe:\n",
    "                                print(f\"PicklingError for user {user_id}: {pe}\")\n",
    "                                continue  # skip this user and continue with the next one\n",
    "\n",
    "                        pbar.update(1)\n",
    "\n",
    "            except IOError as e:\n",
    "                print(f\"IOError: Failed to open or write to file {output_file}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error while writing to file: {e}\")\n",
    "    \n",
    "    except OSError as e:\n",
    "        print(f\"OSError: Failed to create directory for {output_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    \n",
    "    print(f\"User similarity results have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'data/ml-20m/userCF_sim.pkl'\n",
    "userCF_sim = get_userCF_sim_batch(all_ratings_matrix, user_index, item_index, batch_size=1000, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading from json\n",
    "\n",
    "with open('data/ml-20m/itemCF_sim.json', 'r') as f:\n",
    "    itemCF_sim1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'data\\book_crossing\\ratings.csv')\n",
    "df = df.rename(columns={'User-ID':'userId', 'ISBN':'itemId', 'Book-Rating':'rating'})\n",
    "df['userId'].nunique(), df['itemId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'data\\ml-20m\\ratings.csv')\n",
    "df = df.rename(columns={'userId':'userId', 'movieId':'itemId', 'rating':'rating', 'timestamp':'timestamp'})\n",
    "df['userId'].nunique(), df['itemId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading from pkl\n",
    "itemCF_sim2 = {}\n",
    "with open(r'data\\ml-20m\\item_similarity.pkl', 'rb') as file:\n",
    "    i = 1\n",
    "    while True:\n",
    "        try:\n",
    "            itemCF_sim2.update(pickle.load(file))\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(list(itemCF_sim2.keys())[-1])\n",
    "                print(i)\n",
    "            # if i == 2000:\n",
    "            #     break\n",
    "        except EOFError:\n",
    "            break\n",
    "# (125665, 15374, 1000013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading from pkl\n",
    "itemCF_sim1 = {}\n",
    "with open(r'data\\book_crossing\\item_similarity.pkl', 'rb') as file:\n",
    "    i = 1\n",
    "    while True:\n",
    "        try:\n",
    "            itemCF_sim2.update(pickle.load(file))\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(list(itemCF_sim2.keys())[-1])\n",
    "                print(i)\n",
    "            # if i == 2000:\n",
    "            #     break\n",
    "        except EOFError:\n",
    "            break\n",
    "# (27653, 70403, 114978)\n",
    "len(itemCF_sim1.keys()), len(itemCF_sim1[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(itemCF_sim2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(itemCF_sim2[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in itemCF_sim2.items():\n",
    "    print(key, list(zip([i for i in value.keys()][:10],[i for i in value.values()][:10])))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemCF_sim2.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement of weights in collaborative filtering algorithm\n",
    "to be implement..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* base formula\n",
    "  $$\n",
    "  w_{i j}=\\frac{|N(i) \\bigcap N(j)|}{|N(i)|}\n",
    "  $$\n",
    "\n",
    "  + This formula represents the number of users who like both item $i$ and item $j$, as a percentage of the number of users who like item $i$.\n",
    "  + Disadvantage: If item $j$ is a popular item, then its similarity to any item is very high.\n",
    "\n",
    "* Penalize popular items\n",
    "  $$\n",
    "  w_{i j}=\\frac{|N(i) \\cap N(j)|}{\\sqrt{|N(i)||N(j)|}}\n",
    "  $$\n",
    "  \n",
    "  \n",
    "  * According to the problem in the base formula, suppress item $j$. The starting point of the suppression is very simple, which is to divide the denominator by the number of items $j$ purchased.\n",
    "  * At this time, if item $j$ is a popular item, then the corresponding $N(j)$ will also be large, and the penalty will be greater.\n",
    "  \n",
    "* Control the severity of penalties for popular items\n",
    "  $$\n",
    "  w_{i j}=\\frac{|N(i) \\cap N(j)|}{|N(i)|^{1-\\alpha}|N(j)|^{\\alpha}}\n",
    "  $$\n",
    "\n",
    "  * In addition to the method mentioned in the second point, popular items can be penalized when calculating the similarity between items.\n",
    "  * On this basis, the parameter $\\alpha$ can be further introduced, so that the intensity of the penalty for popular items can be determined by controlling the parameter $\\alpha$.\n",
    "\n",
    "* Penalty for active users\n",
    "\n",
    "  * When calculating the similarity between items, the user's activity can be further taken into account.\n",
    "    $$\n",
    "    w_{i j}=\\frac{\\sum_{\\operatorname{\\text {u}\\in N(i) \\cap N(j)}} \\frac{1}{\\log 1+|N(u)|}}{|N(i)|^{1-\\alpha}|N(j)|^{\\alpha}}\n",
    "    $$\n",
    "\n",
    "  + For an abnormally active user, his contribution should be less than that of an inactive user when calculating the similarity between items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem analysis of collaborative filtering algorithm\n",
    "to be implement..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems with collaborative filtering algorithms is that they have weak generalization capabilities:\n",
    "\n",
    "+ That is, collaborative filtering cannot generalize the similarity between two items to the similarity between other items.\n",
    "+ The resulting problem is that **hot items have a strong head effect and are easily similar to a large number of items, while tail items are rarely recommended due to sparse feature vectors**.\n",
    "\n",
    "For example, the following example:\n",
    "\n",
    "![图片](http://ryluo.oss-cn-chengdu.aliyuncs.com/JavaxxhHm3BAtMfsy2AV.png!thumbnail)\n",
    "\n",
    "+ In the matrix on the left, $A, B, C, D$ represent items.\n",
    "+ It can be seen that $D$ is a hot item, and its similarity with $A, B, C$ is relatively large. Therefore, the recommendation system is more likely to recommend $D$ to users who have used $A, B, C$.\n",
    "+ However, the reason why the recommendation system cannot find the similarity between $A, B, C$ is that the interaction data is too sparse and there is a lack of direct data for similarity calculation.\n",
    "\n",
    "So this is the natural defect of collaborative filtering: **The recommendation system has a significant head effect and is weak in processing sparse vectors**.\n",
    "\n",
    "In order to solve this problem and increase the generalization ability of the model at the same time. In 2006, **Matrix Factorization (MF**) was proposed:\n",
    "\n",
    "+ Based on the collaborative filtering co-occurrence matrix, this method uses denser latent vectors to represent users and items, and mines the implicit interests and implicit features of users and items.\n",
    "\n",
    "+ To a certain extent, it makes up for the problem that the collaborative filtering model is not able to process sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Tower-Model based Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a query set $Query: \\left\\{x_{i}\\right\\}_{i=1}^{N}$ and an item set $Item:\\left\\{y_{j}\\right\\}_{j=1}^{M}$.\n",
    "\n",
    "+ $x_{i} \\in X,\\quad y_{j} \\in \\mathcal{Y}$ is a high-dimensional mixture of multiple features (e.g., sparse ID and Dense features).\n",
    "\n",
    "+ The goal of recommendation is to retrieve a series of $item$ subsets for subsequent ranking recommendation tasks for a given $query$.\n",
    "\n",
    "<img src=\"https://ryluo.oss-cn-chengdu.aliyuncs.com/%E5%9B%BE%E7%89%87image-20220506202824884.png\" alt=\"image-20220506202824884\" style=\"zoom:50%;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movielens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ratings.csv\n",
    "    - movieId\n",
    "    - userId\n",
    "    - rating\n",
    "    - timestamp\n",
    "2. m_df.csv\n",
    "    - movieId\n",
    "    - title\n",
    "    - genre\n",
    "3. tags.csv\n",
    "    - userId\n",
    "    - movieId\n",
    "    - tag\n",
    "    - timestamp\n",
    "\n",
    "**Generate Features for 2 tower candidate generation**\n",
    "\n",
    "1. User tower\n",
    "\n",
    "- sparse_feature:\n",
    "    - userId\n",
    "    - user_hist\n",
    "\n",
    "- dense_feature:\n",
    "    - user_mean_rating\n",
    "\n",
    "2. Item tower\n",
    "\n",
    "- sparse_feature:\n",
    "    - movieId\n",
    "    - title\n",
    "    - genres\n",
    "\n",
    "- dense_feature:\n",
    "    - item_mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ratings = pd.read_csv('data/ml-20m/ratings.csv')\n",
    "movies = pd.read_csv('data/ml-20m/movies.csv')\n",
    "\n",
    "movies_ratings.rename(columns={'userId': 'userId', 'movieId': 'itemId', 'rating': 'rating', 'timestamp': 'timestamp'}, inplace=True)\n",
    "movies.rename(columns={'movieId': 'itemId', 'title': 'title', 'genres': 'genres'}, inplace=True)\n",
    "\n",
    "\n",
    "def process_movies_features(movies):\n",
    "    try:\n",
    "        def split_title_time(title):\n",
    "            year_pattern = re.compile(r'\\d{4}')\n",
    "            title = title.strip().replace('\\xa0', '')\n",
    "            title_time = title.split('(')\n",
    "            try:\n",
    "                year = re.findall(year_pattern, title_time[-1])\n",
    "                year = year[0]\n",
    "                title = ' '.join(title_time[:-1])\n",
    "            except IndexError:\n",
    "                year = np.nan\n",
    "            return title.strip(), year\n",
    "        \n",
    "        m_df = movies.copy()\n",
    "        print('splitting title and year...')\n",
    "        m_df['title'], m_df['year'] = zip(*m_df['title'].apply(split_title_time))\n",
    "\n",
    "        m_df['title'] = m_df['title'].astype('str')\n",
    "        # use mode to fill na\n",
    "        m_df['year'] = m_df['year'].fillna(int(m_df['year'].mode()[0])).astype('int')\n",
    "\n",
    "        # title_tfidf\n",
    "        print('initializing title tfidf...')\n",
    "\n",
    "        m_df['title_clean'] = m_df['title'].apply(lambda x: x.lower()) # lowercase\n",
    "        m_df['title_clean'] = m_df['title_clean'].str.replace(r'[^\\w\\s]', '') # remove punctuation\n",
    "        m_df['title_clean'] = m_df['title_clean'].str.replace(r'\\d+', '')  # remove digits\n",
    "        m_df['title_clean'] = m_df['title_clean'].str.replace(r'\\s+', ' ') # remove extra spaces\n",
    "\n",
    "        title_tfidf = TfidfVectorizer(stop_words='english', max_features=100)   # control dimensionality - 100 features\n",
    "        title_tfidf_matrix = title_tfidf.fit_transform(m_df['title_clean'])\n",
    "        m_df.drop(columns=['title_clean'], inplace=True)\n",
    "\n",
    "        m_df = pd.concat([m_df, pd.DataFrame(title_tfidf_matrix.toarray(), columns=[f'title_tfidf_{i}' for i in range(title_tfidf_matrix.shape[1])])], axis=1)\n",
    "        \n",
    "        # year binarization\n",
    "        print('generating year binarization features...')\n",
    "        m_df['is_erlier'] = m_df['year'].apply(lambda x: 1 if int(x) < 1980 else 0)\n",
    "        m_df['is_80s'] = m_df['year'].apply(lambda x: 1 if 1980 <= int(x) < 1990 else 0)\n",
    "        m_df['is_90s'] = m_df['year'].apply(lambda x: 1 if 1990 <= int(x) < 2000 else 0)\n",
    "        m_df['is_00s'] = m_df['year'].apply(lambda x: 1 if 2000 <= int(x) < 2010 else 0)\n",
    "        m_df['is_latest'] = m_df['year'].apply(lambda x: 1 if 2010 <= int(x) < 2020 else 0)\n",
    "\n",
    "        # genre identification\n",
    "        print('generating genre indentification features...')\n",
    "        m_df['genres'].replace('(no genres listed)', '', inplace=True)\n",
    "        m_df['is_comedy'] = m_df['genres'].apply(lambda x: 1 if 'Comedy' in x else 0)\n",
    "        m_df['is_romance'] = m_df['genres'].apply(lambda x: 1 if 'Romance' in x else 0)\n",
    "        m_df['is_action'] = m_df['genres'].apply(lambda x: 1 if 'Action' in x else 0)\n",
    "\n",
    "        # genre_tfidf\n",
    "        print('initializing genre tfidf...')\n",
    "        genre_tfidf = TfidfVectorizer()\n",
    "\n",
    "        m_df['genres_str'] = m_df['genres'].apply(lambda x: x.replace('|', ' '))\n",
    "        \n",
    "        genre_tfidf_matrix = genre_tfidf.fit_transform(m_df['genres_str'])\n",
    "\n",
    "        m_df.drop(columns=['genres_str'], inplace=True)\n",
    "\n",
    "        m_df = pd.concat([m_df, pd.DataFrame(genre_tfidf_matrix.toarray(), columns=[f'genre_tfidf_{i}' for i in range(genre_tfidf_matrix.shape[1])])], axis=1)\n",
    "\n",
    "        print('-'*30+'movie feature processing completed'+'-'*30)\n",
    "\n",
    "        return m_df\n",
    "    \n",
    "    except KeyError as e:\n",
    "        print(f\"During movie feature process, key error during data processing: {e}\")\n",
    "    except MemoryError as e:\n",
    "        print(f\"During movie feature process, memory error, possibly due to long history strings: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"During movie feature process, an unexpected error occurred: {e}\")\n",
    "\n",
    "def feature_process(mr_df, m_df, MAX_HISTORY_LENGTH = 50):\n",
    "    try:\n",
    "\n",
    "        feature_df = mr_df.copy()\n",
    "\n",
    "        feature_df['item_mean_rating'] = feature_df.groupby('itemId')['rating'].transform('mean').apply(lambda x: round(x, 2)).astype('float32')\n",
    "        feature_df['user_mean_rating'] = feature_df.groupby('userId')['rating'].transform('mean').apply(lambda x: round(x, 2)).astype('float32')\n",
    "\n",
    "        print('sorting by userId and timestamp...')\n",
    "        feature_df = feature_df.sort_values(by=['userId', 'timestamp'])\n",
    "\n",
    "        feature_df['user_hist'] = ''\n",
    "        user_history_dict = {}\n",
    "\n",
    "        # Iterate through rows, building user history, limiting history length to MAX_HISTORY_LENGTH\n",
    "        for index, row in tqdm(feature_df.iterrows(), total=len(feature_df), desc=\"Processing user history\"):\n",
    "            user_id = row['userId']\n",
    "            item_id = row['itemId']\n",
    "\n",
    "            if user_id not in user_history_dict:\n",
    "                user_history_dict[user_id] = []\n",
    "\n",
    "            # Limit history to the most recent MAX_HISTORY_LENGTH records\n",
    "            feature_df.at[index, 'user_hist'] = '|'.join(map(str, user_history_dict[user_id][-MAX_HISTORY_LENGTH:]))\n",
    "\n",
    "            user_history_dict[user_id].append(item_id)\n",
    "\n",
    "        print('merging with item features...')\n",
    "        feature_df = pd.merge(feature_df, m_df, on='itemId', how='left')\n",
    "\n",
    "        print('sorting by itemId and userId...')\n",
    "        feature_df.sort_values(by=['itemId', 'userId'], inplace=True)\n",
    "        feature_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        print('-'*30+'interaction feature processing completed'+'-'*30)\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"During interaction feature process, key error during data processing: {e}\")\n",
    "    except MemoryError as e:\n",
    "        print(f\"During interaction feature process, memory error, possibly due to long history strings: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"During interaction feature process, an unexpected error occurred: {e}\")\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "# feature_df = feature_process(mr_df, m_df, MAX_HISTORY_LENGTH = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_feature_process(mr_df, m_df, batch_size=10000):\n",
    "    try:\n",
    "        \n",
    "        users = list(pd.unique(mr_df.userId))\n",
    "        num_users = len(users)\n",
    "        for i in range(0, num_users, batch_size):\n",
    "            \n",
    "            print('processing users {} to {}'.format(i, i+batch_size))\n",
    "            users_batch = users[i:i+batch_size]\n",
    "            mr_df_batch = mr_df[mr_df.userId.isin(users_batch)]\n",
    "            feature_df = feature_process(mr_df_batch, m_df, MAX_HISTORY_LENGTH = 50)\n",
    "\n",
    "            feature_df.to_parquet(f'data/ml-20m/feature_df_{int(i/10000)}.parquet')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"During batch_feature_process, an unexpected error occurred: {e}\")\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = process_movies_features(movies)\n",
    "mr_df = movies_ratings.copy()\n",
    "batch_feature_process(mr_df, movies, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ratings['userId'].value_counts().max(), movies_ratings['userId'].value_counts().min(), movies_ratings['userId'].value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activeness = pd.DataFrame(movies_ratings['userId'].value_counts())\n",
    "# flatten multi-index\n",
    "user_activeness.reset_index(inplace=True)\n",
    "user_activeness.columns = ['userId', 'num_ratings']\n",
    "user_activeness.sort_values(by='num_ratings', ascending=False, inplace=True)\n",
    "user_activeness.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activeness.shape[0], user_activeness[user_activeness['num_ratings'] < 3].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activeness['log_num_ratings'] = np.log10(user_activeness['num_ratings'])\n",
    "# log-log plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "density, bins,_ = plt.hist(user_activeness['num_ratings'], bins=20, density=True, alpha=0)\n",
    "log_density = np.log(density + 1e-10)\n",
    "log_bins = np.log(bins)\n",
    "\n",
    "plt.plot(log_bins[:-1], log_density, marker='o',label='PDF')\n",
    "plt.xlabel('log(num_ratings)')\n",
    "plt.ylabel('log(density)')\n",
    "plt.xlim(-0.5, 7)\n",
    "plt.title('Log-log plot of user activity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of number of ratings per user\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(movies_ratings['userId'].value_counts(), bins=100, color='skyblue', edgecolor='black', linewidth=1.2)\n",
    "plt.title('Distribution of Number of Ratings per User')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Number of Users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paquet files\n",
    "feature_df = pd.read_parquet('data/ml-20m/feature_df_0.parquet')\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_csv('data/ml-20m/m_df_features.csv', index=False)\n",
    "feature_df.to_csv('data/ml-20m/interaction_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature df to a pkl file\n",
    "feature_df.to_pickle('data/ml-20m/feature_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book-Crossing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- books_df\n",
    "    - title: sparse\n",
    "    - author: sparse\n",
    "    - year: density\n",
    "    - publisher: sparse\n",
    "    - itemId: sparse\n",
    "- user_df\n",
    "    - age: density\n",
    "    - userId: sparse\n",
    "    - location: sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('data/book_crossing/map_dict.json', 'r') as f:\n",
    "    map_dict = json.load(f)\n",
    "books_ratings = pd.read_csv('data/book_crossing/ratings.csv')\n",
    "books_ratings['itemId'] = books_ratings['ISBN'].apply(lambda x: map_dict[x])\n",
    "books_ratings = books_ratings.rename(columns={'User-ID':'userId', 'Book-Rating':'rating'})\n",
    "books_ratings.drop(columns=['ISBN'], inplace=True)\n",
    "\n",
    "books_df = pd.read_csv('data/book_crossing/Books_modified.csv', na_values=\"NULL\")\n",
    "books_df = books_df[['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher']]\n",
    "books_df['itemId'] = books_df['ISBN'].map(map_dict)\n",
    "books_df.dropna(inplace=True, axis=0)\n",
    "books_df['itemId'] = books_df['itemId'].astype('int')\n",
    "books_df = books_df.drop(columns=['ISBN'])\n",
    "books_df = books_df.rename(columns={'Book-Title':'title', 'Book-Author':'author', 'Year-Of-Publication':'year', 'Publisher':'publisher'})\n",
    "\n",
    "user_df = pd.read_csv('data/book_crossing/Users.csv')\n",
    "user_df = user_df.rename(columns={'User-ID':'userId', 'Location':'location', 'Age':'age'})\n",
    "user_df['userId'] = user_df['userId'].astype('int')\n",
    "user_df['age'] = user_df['age'].replace(0, np.nan)\n",
    "user_df['age'] = user_df['age'].fillna(user_df['age'].mean()).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_df = pd.read_csv('data/book_crossing/Books.csv')\n",
    "# # books_df[books_df['Year-Of-Publication']=='DK Publishing Inc']['Image-URL-L'] = books_df[books_df['Year-Of-Publication']=='DK Publishing Inc']['Image-URL-M']\n",
    "# # books_df[books_df['Year-Of-Publication']=='DK Publishing Inc']['Image-URL-M'] = books_df[books_df['Year-Of-Publication']=='DK Publishing Inc']['Image-URL-S']\n",
    "# # books_df[books_df['Year-Of-Publication']=='DK Publishing Inc']['Image-URL-S'] = books_df[books_df['Year-Of-Publication']=='DK Publishing Inc']['Publisher']\n",
    "# # books_df[books_df['Year-Of-Publication']=='DK Publishing Inc']['Publisher'] = books_df[books_df['Year-Of-Publication']=='DK Publishing Inc']['Year-Of-Publication']\n",
    "# # books_df[books_df['Year-Of-Publication']=='DK Publishing Inc']['Book-Author'] = np.nan\n",
    "# # books_df[books_df['Year-Of-Publication']=='DK Publishing Inc']['Year-Of-Publication'] = 2000\n",
    "# books_df.iloc[209538,2:] = books_df.iloc[209538,2:].shift(1)\n",
    "# books_df.iloc[221678,2:] = books_df.iloc[221678,2:].shift(1)\n",
    "# books_df.iloc[220731,2:] = books_df.iloc[220731,2:].shift(1)\n",
    "# # books_df['Book-Author'] = books_df['Book-Author'].astype('str')\n",
    "# # books_df['Year-Of-Publication'] = books_df['Year-Of-Publication'].astype('int')\n",
    "# # books_df['Publisher'] = books_df['Publisher'].astype('str')\n",
    "# # books_df['Image-URL-S'] = books_df['Image-URL-S'].astype('str')\n",
    "# # books_df['Image-URL-M'] = books_df['Image-URL-M'].astype('str')\n",
    "# # books_df['Image-URL-L'] = books_df['Image-URL-L'].astype('str')\n",
    "# # books_df['Book-Title'] = books_df['Book-Title'].astype('str')\n",
    "# books_df['ISBN'] = books_df['ISBN'].astype('str')\n",
    "# books_df['Book-Title'] = books_df['Book-Title'].astype('str')\n",
    "# books_df['Year-Of-Publication'] = books_df['Year-Of-Publication'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_df[books_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_df.to_csv('data/book_crossing/Books_modified.csv', index=False, na_rep=\"NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_book_features(books_df):\n",
    "    \n",
    "    print('processing book features...')\n",
    "    b_df = books_df.copy()\n",
    "\n",
    "    print('tfidf on book title...')\n",
    "    b_df['title'] = b_df['title'].astype('str')\n",
    "    title_tfidf = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "    b_df['title_clean'] = b_df['title'].apply(lambda x: x.lower()) # lowercase\n",
    "    b_df['title_clean'] = b_df['title_clean'].str.replace(r'[^\\w\\s]', '') # remove punctuation\n",
    "    b_df['title_clean'] = b_df['title_clean'].str.replace(r'\\d+', '')  # remove digits\n",
    "    b_df['title_clean'] = b_df['title_clean'].str.replace(r'\\s+', ' ') # remove extra spaces\n",
    "    \n",
    "    title_tfidf_matrix = title_tfidf.fit_transform(b_df['title_clean'])\n",
    "    b_df.drop(columns=['title_clean'], inplace=True)\n",
    "    b_df = pd.concat([b_df, pd.DataFrame(title_tfidf_matrix.toarray(), columns=[f'title_tfidf_{i}' for i in range(title_tfidf_matrix.shape[1])])], axis=1)\n",
    "\n",
    "    print('binarizing year...')\n",
    "    b_df['year'] = b_df['year'].fillna(int(b_df['year'].mode()[0])).astype('int')\n",
    "    b_df['is_erlier'] = b_df['year'].apply(lambda x: 1 if int(x) < 1980 else 0)\n",
    "    b_df['is_80s'] = b_df['year'].apply(lambda x: 1 if 1980 <= int(x) < 1990 else 0)\n",
    "    b_df['is_90s'] = b_df['year'].apply(lambda x: 1 if 1990 <= int(x) < 2000 else 0)\n",
    "    b_df['is_00s'] = b_df['year'].apply(lambda x: 1 if 2000 <= int(x) < 2010 else 0)\n",
    "    b_df['is_latest'] = b_df['year'].apply(lambda x: 1 if 2010 <= int(x) < 2020 else 0)\n",
    "\n",
    "    b_df['book_age'] = 2024 - b_df['year']\n",
    "\n",
    "    print('-'*30+'book feature processing completed'+'-'*30)\n",
    "    return b_df\n",
    "\n",
    "\n",
    "def generate_user_features(user_df):\n",
    "\n",
    "    print('processing user features...')\n",
    "    u_df = user_df.copy()\n",
    "\n",
    "    # lower case location\n",
    "    print('pricessing location...')\n",
    "    u_df['location'] = u_df['location'].apply(lambda x: x.lower())\n",
    "    u_df['location'] = u_df['location'].apply(lambda x: x if len(x.split(',')) <=4 or len(x.split(',')) >= 2 else \"Other\")\n",
    "\n",
    "    # extract country\n",
    "    print('extracting country...')\n",
    "    u_df['country'] = u_df['location'].apply(lambda x: x.split(',')[-1].strip())\n",
    "    # convert rare countries to 'Other' -- counts less than 100\n",
    "    countr_map = u_df['country'].value_counts().to_dict()\n",
    "    u_df['country'] = u_df['country'].apply(lambda x: x if countr_map[x] > 100 else 'Other')\n",
    "    countr_map = {}\n",
    "\n",
    "    print('processing age binarization...')\n",
    "    # binarize age\n",
    "    u_df['generation'] = u_df['age'].apply(lambda x: 'Gen Z' if 0 <= x < 25 else 'Millenial' if 25 <= x < 40 else 'Gen X' if 40 <= x < 55 else 'Boomer' if 55 <= x < 75 else 'Silent' if 75 <= x < 95 else 'Greatest')\n",
    "\n",
    "    u_df.rename(columns={'age':'user_age'}, inplace=True)\n",
    "\n",
    "    print('-'*30+'user feature processing completed'+'-'*30)\n",
    "    return u_df\n",
    "\n",
    "def feature_process(br_df, b_df, u_df):\n",
    "    try:\n",
    "\n",
    "        feature_df = br_df.copy()\n",
    "\n",
    "        feature_df['item_mean_rating'] = feature_df.groupby('itemId')['rating'].transform('mean').apply(lambda x: round(x, 2)).astype('float32')\n",
    "        feature_df['user_mean_rating'] = feature_df.groupby('userId')['rating'].transform('mean').apply(lambda x: round(x, 2)).astype('float32')\n",
    "\n",
    "        print('merging with item features...')\n",
    "        feature_df = pd.merge(feature_df, b_df, on='itemId', how='left')\n",
    "\n",
    "        print('merging with user features...')\n",
    "        feature_df = pd.merge(feature_df, u_df, on='userId', how='left')\n",
    "\n",
    "        print('sorting by itemId and userId...')\n",
    "        feature_df.sort_values(by=['itemId', 'userId'], inplace=True)\n",
    "        feature_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        feature_df['book-user_age_crossing'] = feature_df['user_age'] * feature_df['book_age']\n",
    "        feature_df['book-user_age_crossing'] = feature_df['book-user_age_crossing'].astype('int')\n",
    "\n",
    "        print('-'*30+'interaction feature processing completed'+'-'*30)\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"During interaction feature process, key error during data processing: {e}\")\n",
    "    except MemoryError as e:\n",
    "        print(f\"During interaction feature process, memory error, possibly due to long history strings: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"During interaction feature process, an unexpected error occurred: {e}\")\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "def batch_feature_process(br_df, b_df, u_df, batch_size):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        users = list(pd.unique(br_df.userId))\n",
    "        num_users = len(users)\n",
    "        \n",
    "        for i in range(0, num_users, batch_size):\n",
    "            \n",
    "            print('processing users {} to {}'.format(i, i+batch_size))\n",
    "            users_batch = users[i:i+batch_size]\n",
    "            br_df_batch = br_df[br_df.userId.isin(users_batch)]\n",
    "            feature_df = feature_process(br_df_batch, b_df, u_df)\n",
    "\n",
    "            feature_df.to_parquet(f'data/book_crossing/feature_df_{int(i/batch_size)}.parquet')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"During batch_feature_process, an unexpected error occurred: {e}\")\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df = generate_book_features(books_df)\n",
    "u_df = generate_user_features(user_df)\n",
    "br_df = books_ratings.copy()\n",
    "batch_feature_process(br_df, b_df, u_df, batch_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading from pkl\n",
    "itemCF_sim2 = {}\n",
    "with open('data/book_crossing/item_similarity.pkl', 'rb') as file:\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            item = pickle.load(file)\n",
    "            itemCF_sim2.update(item)\n",
    "            # print(item)\n",
    "            i+=1\n",
    "            # print(i)\n",
    "            # if i == 10:\n",
    "            #     break\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemCF_sim1 = pd.read_parquet(r'data\\book_crossing\\item_similarity_matrix.parquet')\n",
    "userCF_sim1 = pd.read_parquet(r'data\\book_crossing\\user_similarity_matrix.parquet')\n",
    "print(itemCF_sim1.shape, userCF_sim1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemCF_sim1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values != 0\n",
    "print(f'itemCF sim matrix sparsity_rate:{itemCF_sim2[itemCF_sim2 != 0].count().sum()/itemCF_sim2.size * 100}%')\n",
    "print(f'itemCF sim matrix sparsity_rate:{userCF_sim2[userCF_sim2 != 0].count().sum()/itemCF_sim2.size * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values != 0\n",
    "print(f'itemCF sim matrix sparsity_rate:{itemCF_sim1[itemCF_sim1 != 0].count().sum()/itemCF_sim1.size * 100}%')\n",
    "print(f'userCF sim matrix sparsity_rate:{userCF_sim1[userCF_sim1 != 0].count().sum()/itemCF_sim1.size * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemCF_sim2 = pd.read_parquet(r'data\\ml-20m\\item_similarity_matrix.parquet')\n",
    "userCF_sim2 = pd.read_parquet(r'data\\ml-20m\\user_similarity_matrix.parquet')\n",
    "print(itemCF_sim2.shape, userCF_sim2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values != 0\n",
    "print(f'itemCF sim matrix sparsity_rate:{itemCF_sim2[itemCF_sim2 != 0].count().sum()/itemCF_sim2.size * 100}%')\n",
    "print(f'userCF sim matrix sparsity_rate:{userCF_sim2[userCF_sim2 != 0].count().sum()/itemCF_sim2.size * 100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu_sd6125_recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
